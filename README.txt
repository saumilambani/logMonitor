GENERAL NOTES:
* watchdog (logMonitor) 
- A task that monitors access.log files. It provides a snapshot summary every 
  10 seconds. It also generates an alert in case the average traffic over the
  past two minutes has breached a threshold (and when it return back to below
  the threshold).

* LogSimulator
- A task to generate mock access logs. 
  The interval between two messages is varied with a deterministic component 
  and a random component in order to simulate varied traffic conditions. 

* Directory Structure
consoleLogs:
--log : folder containing log files for the simulator and the monitor 
--logSimulator : Task to generate mock logs
--logMonitor : Task to monitor and alert events based on access logs
--data : folder containing access log 
--createConfig : Folder containing script to generate config file :console.cfg
--gui : folder to plot real time data from monitoring task
setupEnv.sh : shell script which needs to be sourced to set up the environment
  and the configuration
config.cfg : Generaed configuration file
logSim.sh : script to kick off logSimulator task 
watchdog.sh : script to kick off the monitor

CONFIGURATION:
* configuration file (config.cfg) is generated by the script
  createConfig/createConfig.py
  The description of the config parameters can be found in createConfig.py

INSTRUCTIONS TO RUN:
* Instructions to run the program:
1) Setup the evironment: Source the setupEnv script in the base folder
   ". setupEnv.sh" (for bash shell)

2) Run the logSimulator in a seperate terminal or in background to generate 
   randomized logs:
   ./logSim.sh

3) Run the watchdog program : 
   ./watchdog.py <time> 
   time - number of seconds you wish to run the watchdog. If no time is 
   provided will continue running till keyboard interrupt (ctrl c)

TESTING:
- The logSimulator generates the logs at varying speed and over time should 
  generate alert messages for breaching threshold and recovering.

KNOWN CONCERNS:
- LogSimulator needs to be running before we start the watchdog, else watchdog
  does not do anything
- Documentation is done only to assist with code and implementation, but does
  not follow best practices for markup 
- Assumed no (or very small) lag between time of request (time stamp in access)
  log and the time when the entry appears in the log. Under this assumption, 
  the time stamp on access log is ignored and the time when the log entry 
  appears in the file is used. If required, this can be changed to use time 
  stamp from the file or have an alarm if the access entries are lagging
  significantly to the current time.  
- The first 2 minutes are ramp up time for the watchdog, where it is still 
  collecting data for the average of the first two minutes. During this period 
  an alert is generated only if the total number of messages received during the 
  ramp up time are more than what is required for entire two minutes.  
- The current average traffic calculation for the previous two minutes 
  does a simple summation over the entire queue. This can be optimized if we 
  are working with a larger queue by considering the current mean, new entry
  and the exiting entry, without passing over the entire queue. Further, the 
  queue only consists of count currently, we can extend this to have many more
  intersting aspects, such as, alert if the most popular section changed over 
  time.

COOL ENHANCEMENTS (Future work):
- I created a gui dictionary, but did not get time to actually map the data 
  to the graphs. Would be nice to have a dashboard where we can graph various
  statistics
- We can have a feature for Predict future traffic using ARMA or EWMA. We 
  can also leverage on statistical quality control theory to generate new 
  alerts.
- A concept, say 'histologs' would be nice to carry out statistics and check 
  if thresholds were breached over historic logs. Can ask user the start 
  and end time and scrape through the logs to find based on our rules if 
  any alerts would have trigerred. Lot of the infra structure can be re used 
  for this
- If the 'ramp up' time for watchdog mentioned in the Known Concerns section 
  is significant, we can scrape through older logs and fill the count 
  queue to get rid of the ramp up time 
- Require an alert mechanism if the lag caused by processing is above a certain
  limit (in case number of hits is very high)
- In the above scenario, we may consider not making the reader thread do the 
  summary statistics, but create a seperate thread which knows section of the 
  file to be worked on and does the summary in the background. 
- A fancy log simulator which allows user to customize traffic patterns, such
  as, sine or exponential based would enhance testing
